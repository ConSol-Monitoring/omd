From 198eefc49f25833bfc2f6754b2757f852d716453 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Thu, 25 Jan 2024 15:33:54 +0100
Subject: [PATCH 1/9] logger: use millisecond precision when logging timestamps

---
 src/logger.c | 11 +++++++----
 1 file changed, 7 insertions(+), 4 deletions(-)

diff --git a/src/logger.c b/src/logger.c
index 7ac0c9d..975da30 100644
--- a/src/logger.c
+++ b/src/logger.c
@@ -27,7 +27,7 @@
 #include <stdarg.h>
 #include <stdio.h>
 #include <string.h>
-#include <time.h>
+#include <sys/time.h>
 #include <pthread.h>
 #include <syslog.h>
 
@@ -121,9 +121,12 @@ void logger(int priority, const char *loginfo, ...)
         if (g_logfile) {
             /* write date/time */
             char timestring[64];
-            time_t now_t = time(0);
-            struct tm now; localtime_r(&now_t, &now);
-            strftime(timestring, 64, "%F %T ", &now);
+            struct timeval tv;
+            gettimeofday(&tv, NULL);
+            struct tm now; localtime_r(&tv.tv_sec, &now);
+            strftime(timestring, 64, "[%F %T", &now);
+            fputs(timestring, g_logfile);
+            snprintf(timestring, 64, ".%03ld] ", tv.tv_usec/1000);
             fputs(timestring, g_logfile);
 
             /* write log message */

From ffa0dc10afdc547179ccab7dc08f64a0df901ad4 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Thu, 25 Jan 2024 17:55:26 +0100
Subject: [PATCH 2/9] logcache: avoid reading files outside of requested
 timerange

logfile now reads the last timestamp of a logfile as well and uses this
to select the required logfiles for a given query.

previously, getting logs for one day might have opened and parsed 3 logfiles.
One before the selected day, the day itself and one day afterwards. With
this patch only one file is parsed, making the logs query 3x as fast.
---
 src/LogCache.cc |  4 +++-
 src/Logfile.cc  | 52 +++++++++++++++++++++++++++++++++++++++++++++++++
 src/Logfile.h   |  4 +++-
 src/TableLog.cc | 13 ++++++++++---
 4 files changed, 68 insertions(+), 5 deletions(-)

diff --git a/src/LogCache.cc b/src/LogCache.cc
index c0bdd61..07b47eb 100644
--- a/src/LogCache.cc
+++ b/src/LogCache.cc
@@ -93,7 +93,7 @@ bool LogCache::logCachePreChecks()
         logger(LG_INFO, "Warning: no logfile found, not even %s", log_file);
         return false;
     }
-    // Has Nagios rotated logfiles? => Update
+    // Has Naemon rotated logfiles? => Update
     // our file index. And delete all memorized
     // log messages.
     if (last_log_rotation > _last_index_update) {
@@ -119,6 +119,7 @@ void LogCache::forgetLogfiles()
 
 void LogCache::updateLogfileIndex()
 {
+    logger(LG_DEBUG, "LogCache::updateLogfileIndex()");
     _last_index_update = time(0);
     // We need to find all relevant logfiles. This includes
     // directory.
@@ -151,6 +152,7 @@ void LogCache::updateLogfileIndex()
 
 void LogCache::scanLogfile(char *path, bool watch)
 {
+    logger(LG_DEBUG, "LogCache::scanLogfile: %s", path);
     Logfile *logfile = new Logfile(path, watch);
     time_t since = logfile->since();
     if (since) {
diff --git a/src/Logfile.cc b/src/Logfile.cc
index d3e569a..8a983b5 100644
--- a/src/Logfile.cc
+++ b/src/Logfile.cc
@@ -40,6 +40,7 @@ extern unsigned long g_max_lines_per_logfile;
 Logfile::Logfile(const char *path, bool watch)
   : _path(strdup(path))
   , _since(0)
+  , _end(0)
   , _watch(watch)
   , _inode(0)
   , _lineno(0)
@@ -291,3 +292,54 @@ char *Logfile::readIntoBuffer(int *size)
     close(fd);
     return buffer;
 }
+
+time_t Logfile::end()
+{
+    if(_end > 0)
+        return _end;
+
+    int fd = open(_path, O_RDONLY);
+    if (fd < 0) {
+        logger(LG_WARN, "Cannot open %s for reading: %s", _path, strerror(errno));
+        return 0;
+    }
+
+    int BUFFER_SIZE = 50;
+    char buffer[BUFFER_SIZE];
+
+    off_t o = lseek(fd, -BUFFER_SIZE, SEEK_END);
+    if (o == -1) {
+        logger(LG_WARN, "Cannot seek to end of %s: %s", _path, strerror(errno));
+        close(fd);
+        return 0;
+    }
+
+    // search last newline which is followed by [
+    for(int i = 1; i <= 100 ;i++) {
+        off_t pos = (-BUFFER_SIZE*i)+i;
+        off_t o = lseek(fd, pos, SEEK_END);
+        if (o == -1) {
+            logger(LG_WARN, "Cannot seek to end of %s: %s", _path, strerror(errno));
+            close(fd);
+            return 0;
+        }
+        if(read(fd, buffer, BUFFER_SIZE) <= 0) {
+            close(fd);
+            return 0;
+        }
+        for (int j = BUFFER_SIZE - 2; j >= 0; j--) {
+            if(buffer[j] == '\n' && buffer[j+1] == '[') {
+                lseek(fd, pos+j+2, SEEK_END);
+                read(fd, buffer, 10);
+                buffer[10] = '\x0';
+                _end = atoi(buffer);
+                break;
+            }
+        }
+        if(_end > 0)
+            break;
+    }
+
+    close(fd);
+    return _end;
+}
\ No newline at end of file
diff --git a/src/Logfile.h b/src/Logfile.h
index 07eb947..dd02f5c 100644
--- a/src/Logfile.h
+++ b/src/Logfile.h
@@ -45,6 +45,7 @@ class Logfile
 private:
     char      *_path;
     time_t     _since;         // time of first entry
+    time_t     _end;           // time of last entry
     bool       _watch;         // true only for current logfile
     ino_t      _inode;         // needed to detect switching
     fpos_t     _read_pos;      // read until this position
@@ -63,6 +64,8 @@ class Logfile
     void load(LogCache *LogCache, time_t since, time_t until, unsigned logclasses);
     void flush();
     time_t since() { return _since; }
+    time_t end();
+    bool watch() { return _watch; }
     unsigned classesRead() { return _logclasses_read; }
     long numEntries() { return _entries.size(); }
     logfile_entries_t* getEntriesFromQuery(Query *query, LogCache *lc, time_t since, time_t until, unsigned);
@@ -83,4 +86,3 @@ class Logfile
 
 
 #endif // Logfile_h
-
diff --git a/src/TableLog.cc b/src/TableLog.cc
index a75bf5f..f1dcc61 100644
--- a/src/TableLog.cc
+++ b/src/TableLog.cc
@@ -119,6 +119,7 @@ void TableLog::answerQuery(Query *query)
     // to limit the number of logfiles we need to scan and
     // to find the optimal entry point into the logfile
     query->findIntLimits("time", &since, &until);
+    logger(LG_DEBUG, "TableLog: query time limits: from %u / until %u", since, until);
 
     // The second optimization is for log message types.
     // We want to load only those log type that are queried.
@@ -141,16 +142,22 @@ void TableLog::answerQuery(Query *query)
     // Now find newest log where 'until' is contained. The problem
     // here: For each logfile we only know the time of the *first* entry,
     // not that of the last.
-    while (it != g_store->logCache()->logfiles()->begin() && it->first > until) // while logfiles are too new...
+    while (it != g_store->logCache()->logfiles()->begin() && it->first >= until) // while logfiles are too new...
         --it; // go back in history
-    if (it->first > until) { // all logfiles are too new
+    if (it->first >= until) { // all logfiles are too new
         g_store->logCache()->unlockLogCache();
         return;
     }
 
     while (true) {
         Logfile *log = it->second;
-        if (!log->answerQueryReverse(query, g_store->logCache(), since, until, classmask))
+        logger(LG_DEBUG, "TableLog: considering logfile: %s (from %u / until %u)", log->path(), log->since(), log->end());
+        if(!log->watch() && log->end() > 0 && log->end() < since) {
+            logger(LG_DEBUG, "TableLog: skipped, end of logfile older than start of query");
+            // since all other logfiles are even older, we can end here
+            break;
+        }
+        else if (!log->answerQueryReverse(query, g_store->logCache(), since, until, classmask))
             break; // end of time range found
         if (it == g_store->logCache()->logfiles()->begin())
             break; // this was the oldest one

From 39cba5e11081d23cbe67c304579cb2722074d339 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Thu, 1 Feb 2024 11:08:15 +0100
Subject: [PATCH 3/9] fix crash when freeing entries in logcache

std::map erase returns the next iterator and thats the safe
way to erase entries while iterating over the map.

Signed-off-by: Sven Nierlein <sven@consol.de>
---
 src/LogCache.cc          | 26 ++++++++++++--------------
 src/LogCache.h           |  1 -
 src/Logfile.cc           | 12 +++++++++---
 src/Store.cc             |  9 +++++++++
 src/Table.h              |  2 +-
 src/TableLog.cc          | 16 +++++++---------
 src/TableLog.h           |  2 +-
 src/TableStateHistory.cc |  8 --------
 src/TableStateHistory.h  |  2 +-
 9 files changed, 40 insertions(+), 38 deletions(-)

diff --git a/src/LogCache.cc b/src/LogCache.cc
index 07b47eb..e38d57c 100644
--- a/src/LogCache.cc
+++ b/src/LogCache.cc
@@ -42,7 +42,7 @@
 #include "LogCache.h"
 
 extern time_t last_log_rotation;
-
+extern int g_debug_level;
 
 #define CHECK_MEM_CYCLE 1000 /* Check memory every N'th new message */
 
@@ -77,12 +77,18 @@ LogCache::~LogCache()
 
 void LogCache::lockLogCache()
 {
+    if (g_debug_level > 0)
+        logger(LG_INFO, "LogCache: waiting for logcache lock");
     pthread_mutex_lock(&_lock);
+    if (g_debug_level > 0)
+        logger(LG_INFO, "LogCache: got logcache lock");
 }
 
 void LogCache::unlockLogCache()
 {
     pthread_mutex_unlock(&_lock);
+    if (g_debug_level > 0)
+        logger(LG_INFO, "LogCache: released logcache lock");
 }
 
 bool LogCache::logCachePreChecks()
@@ -93,7 +99,7 @@ bool LogCache::logCachePreChecks()
         logger(LG_INFO, "Warning: no logfile found, not even %s", log_file);
         return false;
     }
-    // Has Naemon rotated logfiles? => Update
+    // Has Nagios rotated logfiles? => Update
     // our file index. And delete all memorized
     // log messages.
     if (last_log_rotation > _last_index_update) {
@@ -119,7 +125,8 @@ void LogCache::forgetLogfiles()
 
 void LogCache::updateLogfileIndex()
 {
-    logger(LG_DEBUG, "LogCache::updateLogfileIndex()");
+    if (g_debug_level > 0)
+        logger(LG_INFO, "LogCache::updateLogfileIndex()");
     _last_index_update = time(0);
     // We need to find all relevant logfiles. This includes
     // directory.
@@ -152,7 +159,8 @@ void LogCache::updateLogfileIndex()
 
 void LogCache::scanLogfile(char *path, bool watch)
 {
-    logger(LG_DEBUG, "LogCache::scanLogfile: %s", path);
+    if (g_debug_level > 0)
+        logger(LG_INFO, "LogCache::scanLogfile: %s", path);
     Logfile *logfile = new Logfile(path, watch);
     time_t since = logfile->since();
     if (since) {
@@ -170,16 +178,6 @@ void LogCache::scanLogfile(char *path, bool watch)
         delete logfile;
 }
 
-void LogCache::dumpLogfiles()
-{
-    for (_logfiles_t::iterator it = _logfiles.begin();
-            it != _logfiles.end();
-            ++it)
-    {
-        Logfile *log = it->second;
-    }
-}
-
 /* This method is called each time a log message is loaded
    into memory. If the number of messages loaded in memory
    is to large, memory will be freed by flushing logfiles
diff --git a/src/LogCache.h b/src/LogCache.h
index 9c5a450..1b3aa64 100644
--- a/src/LogCache.h
+++ b/src/LogCache.h
@@ -63,7 +63,6 @@ class LogCache
 private:
     void scanLogfile(char *path, bool watch);
     _logfiles_t::iterator findLogfileStartingBefore(time_t);
-    void dumpLogfiles();
 };
 
 #endif // LogCache_h
diff --git a/src/Logfile.cc b/src/Logfile.cc
index 8a983b5..6eae9bb 100644
--- a/src/Logfile.cc
+++ b/src/Logfile.cc
@@ -35,6 +35,7 @@
 #include "LogCache.h"
 
 extern unsigned long g_max_lines_per_logfile;
+extern int g_debug_level;
 
 
 Logfile::Logfile(const char *path, bool watch)
@@ -143,6 +144,8 @@ void Logfile::load(LogCache *logcache, time_t since, time_t until, unsigned logc
 void Logfile::loadRange(FILE *file, unsigned missing_types,
         LogCache *logcache, time_t since, time_t until, unsigned logclasses)
 {
+    if (g_debug_level > 0)
+        logger(LG_INFO, "Logfile::loadRange: %s", this->path());
     while (fgets(_linebuffer, MAX_LOGLINE, file))
     {
         if (_lineno >= g_max_lines_per_logfile) {
@@ -154,19 +157,22 @@ void Logfile::loadRange(FILE *file, unsigned missing_types,
             logcache->handleNewMessage(this, since, until, logclasses); // memory management
         }
     }
+    if (g_debug_level > 0)
+        logger(LG_INFO, "Logfile::loadRange done: %s", this->path());
 }
 
 long Logfile::freeMessages(unsigned logclasses)
 {
     long freed = 0;
-    for (logfile_entries_t::iterator it = _entries.begin(); it != _entries.end(); ++it)
-    {
+    for (logfile_entries_t::iterator it = _entries.begin(); it != _entries.end();) {
         LogEntry *entry = it->second;
         if ((1 << entry->_logclass) & logclasses)
         {
             delete it->second;
-            _entries.erase(it);
+            it = _entries.erase(it);
             freed ++;
+        } else {
+            it++;
         }
     }
     _logclasses_read &= ~logclasses;
diff --git a/src/Store.cc b/src/Store.cc
index f5fe147..c14eb6e 100644
--- a/src/Store.cc
+++ b/src/Store.cc
@@ -41,6 +41,7 @@
 extern int g_debug_level;
 extern unsigned long g_max_cached_messages;
 extern char *qh_socket_path;
+extern Store *g_store;
 
 Store::Store()
   : _log_cache(g_max_cached_messages)
@@ -187,6 +188,11 @@ void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const cha
     }
     Query query(input, output, table);
 
+    if(table->hasLogcache()) {
+        g_store->logCache()->lockLogCache();
+        g_store->logCache()->logCachePreChecks();
+    }
+
     if (table && !output->hasError()) {
         if (query.hasNoColumns()) {
             table->addAllColumnsToQuery(&query);
@@ -203,4 +209,7 @@ void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const cha
         if (g_debug_level > 0)
             logger(LG_INFO, "Time to process request: %lu us. Size of answer: %d bytes", ustime, output->size());
     }
+
+    if(table->hasLogcache())
+        g_store->logCache()->unlockLogCache();
 }
diff --git a/src/Table.h b/src/Table.h
index c365d3a..2b2a9b7 100644
--- a/src/Table.h
+++ b/src/Table.h
@@ -57,6 +57,7 @@ class Table
     virtual const char *prefixname() { return name(); }
     virtual bool isAuthorized(contact *, void *) { return true; }
     virtual void *findObject(char *objectspec __attribute__ ((__unused__))) { return 0; } // objectspec may be modified while parsing
+    virtual bool hasLogcache() { return false; };
     void clearNatSort();
     void addNatSort(string);
     void addColumn(Column *);
@@ -68,4 +69,3 @@ class Table
 
 
 #endif // Table_h
-
diff --git a/src/TableLog.cc b/src/TableLog.cc
index f1dcc61..e71031c 100644
--- a/src/TableLog.cc
+++ b/src/TableLog.cc
@@ -48,6 +48,7 @@
 #define CHECK_MEM_CYCLE 1000 /* Check memory every N'th new message */
 
 extern Store *g_store;
+extern int g_debug_level;
 
 TableLog::TableLog()
 {
@@ -108,9 +109,6 @@ TableLog::~TableLog()
 
 void TableLog::answerQuery(Query *query)
 {
-    g_store->logCache()->lockLogCache();
-    g_store->logCache()->logCachePreChecks();
-
     int since = 0;
     int until = time(0) + 1;
     // Optimize time interval for the query. In log querys
@@ -119,14 +117,14 @@ void TableLog::answerQuery(Query *query)
     // to limit the number of logfiles we need to scan and
     // to find the optimal entry point into the logfile
     query->findIntLimits("time", &since, &until);
-    logger(LG_DEBUG, "TableLog: query time limits: from %u / until %u", since, until);
+    if (g_debug_level > 0)
+        logger(LG_INFO, "TableLog: query time limits: from %u / until %u", since, until);
 
     // The second optimization is for log message types.
     // We want to load only those log type that are queried.
     uint32_t classmask = LOGCLASS_ALL;
     query->optimizeBitmask("class", &classmask);
     if (classmask == 0) {
-        g_store->logCache()->unlockLogCache();
         return;
     }
 
@@ -145,15 +143,16 @@ void TableLog::answerQuery(Query *query)
     while (it != g_store->logCache()->logfiles()->begin() && it->first >= until) // while logfiles are too new...
         --it; // go back in history
     if (it->first >= until) { // all logfiles are too new
-        g_store->logCache()->unlockLogCache();
         return;
     }
 
     while (true) {
         Logfile *log = it->second;
-        logger(LG_DEBUG, "TableLog: considering logfile: %s (from %u / until %u)", log->path(), log->since(), log->end());
+        if (g_debug_level > 0)
+            logger(LG_INFO, "TableLog: considering logfile: %s (from %u / until %u)", log->path(), log->since(), log->end());
         if(!log->watch() && log->end() > 0 && log->end() < since) {
-            logger(LG_DEBUG, "TableLog: skipped, end of logfile older than start of query");
+            if (g_debug_level > 0)
+                logger(LG_INFO, "TableLog: skipped, end of logfile older than start of query");
             // since all other logfiles are even older, we can end here
             break;
         }
@@ -163,7 +162,6 @@ void TableLog::answerQuery(Query *query)
             break; // this was the oldest one
         --it;
     }
-    g_store->logCache()->unlockLogCache();
 }
 
 
diff --git a/src/TableLog.h b/src/TableLog.h
index 9be88d0..a24910c 100644
--- a/src/TableLog.h
+++ b/src/TableLog.h
@@ -41,10 +41,10 @@ class TableLog : public Table
     const char *name() { return "log"; }
     const char *prefixname() { return "logs"; }
     bool isAuthorized(contact *ctc, void *data);
-    void handleNewMessage(Logfile *logfile, time_t since, time_t until, unsigned logclasses);
     void addColumns(Table *, string prefix, int indirect_offset, bool add_host = true, bool add_service = true);
     void answerQuery(Query *query);
     Column *column(const char *colname); // override in order to handle current_
+    bool hasLogcache() { return true; };
 
 private:
     bool answerQuery(Query *, Logfile *, time_t, time_t);
diff --git a/src/TableStateHistory.cc b/src/TableStateHistory.cc
index dc41101..928ceac 100644
--- a/src/TableStateHistory.cc
+++ b/src/TableStateHistory.cc
@@ -204,9 +204,6 @@ void TableStateHistory::answerQuery(Query *query)
         }
     }
 
-    g_store->logCache()->lockLogCache();
-    g_store->logCache()->logCachePreChecks();
-
     // This flag might be set to true by the return value of processDataset(...)
     _abort_query = false;
 
@@ -226,14 +223,12 @@ void TableStateHistory::answerQuery(Query *query)
     _query->findIntLimits("time", &_since, &_until);
     if (_since == 0) {
         query->setError(RESPONSE_CODE_INVALID_REQUEST, "Start of timeframe required. e.g. Filter: time > 1234567890");
-        g_store->logCache()->unlockLogCache();
         return;
     }
 
     _query_timeframe = _until - _since - 1;
     if (_query_timeframe == 0) {
         query->setError(RESPONSE_CODE_INVALID_REQUEST, "Query timeframe is 0 seconds");
-        g_store->logCache()->unlockLogCache();
         return;
     }
 
@@ -251,7 +246,6 @@ void TableStateHistory::answerQuery(Query *query)
     if (_it_logs->first > _until) {
         // All logfiles are too new, invalid timeframe
         // -> No data available. Return empty result.
-        g_store->logCache()->unlockLogCache();
         return;
     }
 
@@ -544,8 +538,6 @@ void TableStateHistory::answerQuery(Query *query)
         }
     }
     object_blacklist.clear();
-
-    g_store->logCache()->unlockLogCache();
 }
 
 void TableStateHistory::cleanupQuery(Query *query) {
diff --git a/src/TableStateHistory.h b/src/TableStateHistory.h
index 0de5cf8..b33a840 100644
--- a/src/TableStateHistory.h
+++ b/src/TableStateHistory.h
@@ -67,12 +67,12 @@ class TableStateHistory : public Table
     const char *name() { return "statehist"; }
     const char *prefixname() { return "statehist_"; }
     bool isAuthorized(contact *ctc, void *data);
-    void handleNewMessage(Logfile *logfile, time_t since, time_t until, unsigned logclasses);
     void answerQuery(Query *query);
     void cleanupQuery(Query *query);
     Column *column(const char *colname); // override in order to handle current_
     int updateHostServiceState(Query *query, const LogEntry *entry, HostServiceState *state, const bool only_update);
     static void addColumns(Table *);
+    bool hasLogcache() { return true; };
 
 private:
     LogEntry* getPreviousLogentry();

From f296ab80a87572c31a861e11b4d6f45bb722d8c5 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Thu, 1 Feb 2024 14:09:44 +0100
Subject: [PATCH 4/9] logcache: run mem cycle less often

and make logcache erase compile on rhel7.
---
 src/LogCache.cc | 2 +-
 src/Logfile.cc  | 6 ++++--
 2 files changed, 5 insertions(+), 3 deletions(-)

diff --git a/src/LogCache.cc b/src/LogCache.cc
index e38d57c..237bad6 100644
--- a/src/LogCache.cc
+++ b/src/LogCache.cc
@@ -44,7 +44,7 @@
 extern time_t last_log_rotation;
 extern int g_debug_level;
 
-#define CHECK_MEM_CYCLE 1000 /* Check memory every N'th new message */
+#define CHECK_MEM_CYCLE 10000 /* Check memory every N'th new message */
 
 // watch naemon' logfile rotation
 extern char *log_archive_path;
diff --git a/src/Logfile.cc b/src/Logfile.cc
index 6eae9bb..95b4ae4 100644
--- a/src/Logfile.cc
+++ b/src/Logfile.cc
@@ -169,8 +169,10 @@ long Logfile::freeMessages(unsigned logclasses)
         if ((1 << entry->_logclass) & logclasses)
         {
             delete it->second;
-            it = _entries.erase(it);
-            freed ++;
+            logfile_entries_t::iterator entry = it;
+            it++;
+            _entries.erase(entry);
+            freed++;
         } else {
             it++;
         }

From 5af1a947cbaa50614799908082886aae750af56f Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Wed, 7 Feb 2024 14:07:23 +0100
Subject: [PATCH 5/9] logcache: check connection before building logs result

the logcache uses a lock to only server one request at a time. Pending
requests will be queued and served in order, even if the client has
disconnected meanwhile. The log request would be build in this case
and then livestatus detects the broken pipe once it sends out the first
byte.
Better check the client connection once before building the result.
---
 src/OutputBuffer.cc | 22 ++++++++++++++++++++++
 src/OutputBuffer.h  |  1 +
 src/Store.cc        | 19 ++++++++++++++-----
 src/Store.h         |  6 ++----
 src/module.c        |  2 +-
 src/store.cc        |  4 ++--
 src/store.h         |  2 +-
 7 files changed, 43 insertions(+), 13 deletions(-)

diff --git a/src/OutputBuffer.cc b/src/OutputBuffer.cc
index 1a309b4..a1ddbec 100644
--- a/src/OutputBuffer.cc
+++ b/src/OutputBuffer.cc
@@ -144,6 +144,28 @@ void OutputBuffer::writeData(int fd, const char *write_from, int to_write)
     }
 }
 
+bool OutputBuffer::isAlive(int fd)
+{
+    struct timeval tv = {0};
+    fd_set fds;
+    FD_ZERO(&fds);
+    FD_SET(fd, &fds);
+
+    int retval = select(fd + 1, NULL, &fds, NULL, &tv);
+    if (retval > 0 && FD_ISSET(fd, &fds)) {
+        ssize_t w = write(fd, "", 0);
+        if (w < 0) {
+            // select returned file handle, but write failed -> client is gone
+            return false;
+        }
+        // select returned file handle and write succeeded -> client is alive
+        return true;
+    }
+
+    // select returned no file handle -> client is gone
+    return false;
+}
+
 void OutputBuffer::setError(unsigned code, const char *format, ...)
 {
     // only the first error is being returned
diff --git a/src/OutputBuffer.h b/src/OutputBuffer.h
index 1227052..b13cc12 100644
--- a/src/OutputBuffer.h
+++ b/src/OutputBuffer.h
@@ -70,6 +70,7 @@ class OutputBuffer
     bool doKeepalive() { return _do_keepalive; }
     void setError(unsigned code, const char *format, ...);
     bool hasError() { return _error_message != ""; }
+    bool isAlive(int fd);
 
 private:
     void needSpace(unsigned);
diff --git a/src/Store.cc b/src/Store.cc
index c14eb6e..6a93fc3 100644
--- a/src/Store.cc
+++ b/src/Store.cc
@@ -116,7 +116,7 @@ void Store::registerDowntime(nebstruct_downtime_data *d)
     _table_downtimes.addDowntime(d);
 }
 
-bool Store::answerRequest(InputBuffer *input, OutputBuffer *output)
+bool Store::answerRequest(InputBuffer *input, OutputBuffer *output, int fd)
 {
     output->reset();
     int r = input->readRequest();
@@ -131,9 +131,9 @@ bool Store::answerRequest(InputBuffer *input, OutputBuffer *output)
     if (g_debug_level > 0)
         logger(LG_INFO, "Query: %s", line);
     if (!strncmp(line, "GET ", 4))
-        answerGetRequest(input, output, lstrip((char *)line + 4));
+        answerGetRequest(input, output, lstrip((char *)line + 4), fd);
     else if (!strcmp(line, "GET"))
-        answerGetRequest(input, output, ""); // only to get error message
+        answerGetRequest(input, output, "", fd); // only to get error message
     else if (!strncmp(line, "COMMAND ", 8)) {
         answerCommandRequest(unescape_newlines(lstrip((char *)line + 8)), output);
         output->setDoKeepalive(true);
@@ -175,8 +175,9 @@ void Store::answerCommandRequest(const char *command, OutputBuffer *output)
 }
 
 
-void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const char *tablename)
+void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const char *tablename, int fd)
 {
+    bool logcacheLocked = false;
     output->reset();
 
     if (!tablename[0]) {
@@ -190,7 +191,15 @@ void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const cha
 
     if(table->hasLogcache()) {
         g_store->logCache()->lockLogCache();
+        // check if client is still connected, we might have waited too long for the lock
+        if(!output->isAlive(fd)) {
+            output->setError(RESPONSE_CODE_INCOMPLETE_REQUEST, "Client already disconnected");
+            g_store->logCache()->unlockLogCache();
+            return;
+        }
+
         g_store->logCache()->logCachePreChecks();
+        logcacheLocked = true;
     }
 
     if (table && !output->hasError()) {
@@ -210,6 +219,6 @@ void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const cha
             logger(LG_INFO, "Time to process request: %lu us. Size of answer: %d bytes", ustime, output->size());
     }
 
-    if(table->hasLogcache())
+    if(logcacheLocked)
         g_store->logCache()->unlockLogCache();
 }
diff --git a/src/Store.h b/src/Store.h
index fc26566..245578e 100644
--- a/src/Store.h
+++ b/src/Store.h
@@ -74,14 +74,12 @@ class Store
     void registerHostgroup(hostgroup *);
     void registerComment(nebstruct_comment_data *);
     void registerDowntime(nebstruct_downtime_data *);
-    bool answerRequest(InputBuffer *, OutputBuffer *);
+    bool answerRequest(InputBuffer *, OutputBuffer *, int);
 
 private:
     Table *findTable(string name);
-    void answerGetRequest(InputBuffer *, OutputBuffer *, const char *);
+    void answerGetRequest(InputBuffer *, OutputBuffer *, const char *, int fd);
     void answerCommandRequest(const char *, OutputBuffer *);
 };
 
 #endif // Store_h
-
-
diff --git a/src/module.c b/src/module.c
index 79cbecd..b29d07e 100644
--- a/src/module.c
+++ b/src/module.c
@@ -199,7 +199,7 @@ void *client_thread(void *data)
         while (keepalive && !g_should_terminate) {
             if (g_debug_level >= 2 && requestnr > 1)
                 logger(LG_INFO, "Handling request %d on same connection", requestnr);
-            keepalive = store_answer_request(input_buffer, output_buffer);
+            keepalive = store_answer_request(input_buffer, output_buffer, cc);
             flush_output_buffer(output_buffer, cc);
             g_counters[COUNTER_REQUESTS]++;
             requestnr ++;
diff --git a/src/store.cc b/src/store.cc
index fc6814b..c636f7e 100644
--- a/src/store.cc
+++ b/src/store.cc
@@ -75,9 +75,9 @@ void store_register_downtime(nebstruct_downtime_data *d)
     g_store->registerDowntime(d);
 }
 
-int store_answer_request(void *ib, void *ob)
+int store_answer_request(void *ib, void *ob, int fd)
 {
-    return g_store->answerRequest((InputBuffer *)ib, (OutputBuffer *)ob);
+    return g_store->answerRequest((InputBuffer *)ib, (OutputBuffer *)ob, fd);
 }
 
 void *create_outputbuffer(int *termination_flag)
diff --git a/src/store.h b/src/store.h
index 2abe060..3a10ddb 100644
--- a/src/store.h
+++ b/src/store.h
@@ -36,7 +36,7 @@ extern "C"
     void store_deinit();
     void store_register_comment(nebstruct_comment_data *);
     void store_register_downtime(nebstruct_downtime_data *);
-    int  store_answer_request(void *input_buffer, void *output_buffer);
+    int  store_answer_request(void *input_buffer, void *output_buffer, int fd);
     void *create_outputbuffer(int *termination_flag);
     void flush_output_buffer(void *ob, int fd);
     void delete_outputbuffer(void *);

From 173a60a6515fd9132eba4025235e36d90d4d5036 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Wed, 7 Feb 2024 15:17:52 +0100
Subject: [PATCH 6/9] log thread id on higher debug levels

this makes it possibe to connect log entries to specific queries.
---
 src/logger.c | 9 +++++++--
 1 file changed, 7 insertions(+), 2 deletions(-)

diff --git a/src/logger.c b/src/logger.c
index 975da30..b0fe3c4 100644
--- a/src/logger.c
+++ b/src/logger.c
@@ -32,6 +32,7 @@
 #include <syslog.h>
 
 extern char g_logfile_path[];
+extern int g_debug_level;
 pthread_t g_mainthread_id;
 
 /* This protects the log file variable g_logfile to avoid concurrent writes as
@@ -107,9 +108,10 @@ void logger(int priority, const char *loginfo, ...)
 {
     va_list ap;
     va_start(ap, loginfo);
+    pthread_t tid = pthread_self();
 
     /* Only the main process may use the Nagios log methods */
-    if (g_mainthread_id == pthread_self()) {
+    if (g_mainthread_id == tid) {
         char buffer[8192];
         snprintf(buffer, 20, "livestatus: ");
         vsnprintf(buffer + strlen(buffer),
@@ -126,7 +128,10 @@ void logger(int priority, const char *loginfo, ...)
             struct tm now; localtime_r(&tv.tv_sec, &now);
             strftime(timestring, 64, "[%F %T", &now);
             fputs(timestring, g_logfile);
-            snprintf(timestring, 64, ".%03ld] ", tv.tv_usec/1000);
+            if (g_debug_level > 0)
+                snprintf(timestring, 64, ".%03ld][thr-%ld] ", tv.tv_usec/1000, tid);
+            else
+                snprintf(timestring, 64, ".%03ld] ", tv.tv_usec/1000);
             fputs(timestring, g_logfile);
 
             /* write log message */

From 7c5ad0ee7b2290a36e023c180ac3d7eb3f029621 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Wed, 7 Feb 2024 16:28:36 +0100
Subject: [PATCH 7/9] fix crash on stats queries on the logs table

Default sort column on log table was the contact name, which makes no sense.
This was because of the contacts reference columns added at the end which set
natural sort columns.
Set the sort column to time.
---
 src/TableLog.cc | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/src/TableLog.cc b/src/TableLog.cc
index e71031c..513fd99 100644
--- a/src/TableLog.cc
+++ b/src/TableLog.cc
@@ -100,6 +100,9 @@ void TableLog::addColumns(Table *table, string prefix, int indirect_offset, bool
         g_table_services->addColumns(table, "current_service_", (char *)&(ref->_service) - (char *)ref, false /* no hosts table */);
     g_table_contacts->addColumns(table, "current_contact_", (char *)&(ref->_contact) - (char *)ref);
     g_table_commands->addColumns(table, "current_command_", (char *)&(ref->_command) - (char *)ref);
+
+    table->clearNatSort();
+    table->addNatSort( "time" );
 }
 
 

From c3307690854696a53327bcfabff4ac07da5e8720 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Wed, 7 Feb 2024 17:17:45 +0100
Subject: [PATCH 8/9] fix crash if stats queries errors halfway

---
 src/Store.cc | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/src/Store.cc b/src/Store.cc
index 6a93fc3..73790ec 100644
--- a/src/Store.cc
+++ b/src/Store.cc
@@ -211,7 +211,8 @@ void Store::answerGetRequest(InputBuffer *input, OutputBuffer *output, const cha
         gettimeofday(&before, 0);
         query.start();
         table->answerQuery(&query);
-        query.finish();
+        if (!output->hasError()) // crashes on stats queries which result in errors before
+            query.finish();
         table->cleanupQuery(&query);
         gettimeofday(&after, 0);
         unsigned long ustime = (after.tv_sec - before.tv_sec) * 1000000 + (after.tv_usec - before.tv_usec);

From 532addb16e5d1c0a6b0a3aa9ca54926657e15f45 Mon Sep 17 00:00:00 2001
From: Sven Nierlein <sven@consol.de>
Date: Wed, 7 Feb 2024 17:18:14 +0100
Subject: [PATCH 9/9] calculate estimated result size for stats queries

output size is always zero here until we calculate the final result but it would be good to cancel runaway stats queries as well, ex. stats with high cardinality column set
---
 src/Query.cc | 11 +++++++++++
 1 file changed, 11 insertions(+)

diff --git a/src/Query.cc b/src/Query.cc
index 5181405..39b7f59 100644
--- a/src/Query.cc
+++ b/src/Query.cc
@@ -966,6 +966,17 @@ bool Query::processDataset(void *data)
                 if( is_new ) {
                     _current_line++;
                     _sorter.insert( data, _limit+_offset );
+
+                    // make sure we don't create too many aggregation entries. The size is only a rough estimation
+                    // from the last entry mulitplies with the number of entries.
+                    size_t rowsize = 0;
+                    for (_stats_group_spec_t::iterator iit = groupspec.begin(); iit != groupspec.end(); ++iit)
+                        rowsize += sizeof(char*) * strlen((*iit).c_str());
+                    if (_sorter.size() * rowsize > g_max_response_size) {
+                        logger(LG_INFO, "Maximum response size of %d bytes exceeded!", g_max_response_size);
+                        _output->setError(RESPONSE_CODE_LIMIT_EXCEEDED, "Maximum response size of %d reached", g_max_response_size);
+                        return false;
+                    }
                 }
             }
             else
